{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Comparing Baseline training configuration to Experiment: batch_size_64\n",
    "\n",
    "In the baseline experiment, the GPU memory is only ~25% utilized.  If we increase the batch size to more fully utilize the GPU memory,\n",
    "is training speed faster?Notes\n",
    "3 jobs of the same experiment were run concurrently on the same compute (gpu-cluster-64-cores)each training job runs for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"baseline_training_runtime\"\n",
    "experiment = \"batch_size_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get_experiment_by_name(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query mlflow for experiment jobs and metrics\n",
    "baseline_df = mlflow.search_runs(\n",
    "    experiment_names=[baseline],\n",
    "    # filter_string=\"attributes.status = 'Finished'\",\n",
    ").assign(experiment_name=baseline)\n",
    "\n",
    "experiment_df = mlflow.search_runs(\n",
    "    experiment_names=[experiment],\n",
    "    # filter_string=\"attributes.status = 'Finished'\",\n",
    ").assign(experiment_name=experiment)\n",
    "\n",
    "df = pd.concat([baseline_df, experiment_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate minutes elapsed for each job\n",
    "df = df.assign(\n",
    "    duration=lambda df: (df.end_time - df.start_time),\n",
    "    minutes=lambda df: (df.end_time - df.start_time).astype(int) / (1e9 * 60),\n",
    ")\n",
    "df[[\"experiment_name\", \"minutes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that baseline sample mean duration is 'greater' than the experiment sample mean\n",
    "# for now, we ignore multiple comparison corrections because there's only a single comparison :)\n",
    "# multiple comparison test: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.dunnett.html\n",
    "sample_a = df[df.experiment_name == baseline].minutes\n",
    "sample_b = df[df.experiment_name == experiment].minutes\n",
    "stats = ttest_ind(sample_a, sample_b, equal_var=False, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)\n",
    "print(stats.confidence_interval())\n",
    "# The confidence interval does not include zero, so we can conclude that\n",
    "# sample mean of the baseline is greater than the sample mean of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = (\n",
    "    df[[\"experiment_name\", \"minutes\"]]\n",
    "    .groupby(\"experiment_name\")\n",
    "    .agg(\n",
    "        mean=(\"minutes\", \"mean\"),\n",
    "        var=(\"minutes\", \"var\"),\n",
    "        std=(\"minutes\", \"std\"),\n",
    "        min=(\"minutes\", \"min\"),\n",
    "        max=(\"minutes\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean = stats_df[stats_df.experiment_name == baseline][\"mean\"].iloc[0]\n",
    "experiment_mean = stats_df[stats_df.experiment_name == experiment][\"mean\"].iloc[0]\n",
    "\n",
    "diff = baseline_mean - experiment_mean\n",
    "diff_percent = diff / baseline_mean * 100\n",
    "print(f\"{diff_percent:.2f}% faster\")\n",
    "print(f\"{diff:.2f} minutes faster on average\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "methane-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
