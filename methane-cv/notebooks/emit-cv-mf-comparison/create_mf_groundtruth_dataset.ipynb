{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6c1370-f8c6-4c44-9cfd-748430866d4d",
   "metadata": {},
   "source": [
    "# Create MF ground truth dataset\n",
    "\n",
    "Set up the config files to run our EMIT MF satellite data pipeline over the same \"ground truth\" sites used by the EMIT CV training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9991b0e-a9ae-4f6d-8c94-527d92c5be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdd0daf-d1a4-4a42-8de0-7595ad4e58dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>quantification_kg_h</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.821792</td>\n",
       "      <td>-111.786123</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Casa Grande, AZ</td>\n",
       "      <td>755.0369</td>\n",
       "      <td>SBR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.821792</td>\n",
       "      <td>-111.786123</td>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>Casa Grande, AZ</td>\n",
       "      <td>943.2397</td>\n",
       "      <td>SBR 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.346770</td>\n",
       "      <td>-101.798720</td>\n",
       "      <td>2024-02-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18163.0000</td>\n",
       "      <td>IMEO Notified Plumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.300740</td>\n",
       "      <td>-96.130340</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92358.0000</td>\n",
       "      <td>IMEO Notified Plumes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.075490</td>\n",
       "      <td>-103.278800</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1553.0000</td>\n",
       "      <td>IMEO Notified Plumes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon        date             site  quantification_kg_h  \\\n",
       "0  32.821792 -111.786123  2024-12-02  Casa Grande, AZ             755.0369   \n",
       "1  32.821792 -111.786123  2024-11-28  Casa Grande, AZ             943.2397   \n",
       "2  31.346770 -101.798720  2024-02-12              NaN           18163.0000   \n",
       "3  38.300740  -96.130340  2024-04-05              NaN           92358.0000   \n",
       "4  32.075490 -103.278800  2024-04-25              NaN            1553.0000   \n",
       "\n",
       "                 source  \n",
       "0              SBR 2024  \n",
       "1              SBR 2024  \n",
       "2  IMEO Notified Plumes  \n",
       "3  IMEO Notified Plumes  \n",
       "4  IMEO Notified Plumes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_sites = pd.read_csv(\"../../src/data/ancillary/EMIT_ground_truth_plumes.csv\")\n",
    "gt_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2da69-1409-4d2c-a5cd-a64bf6e5a3d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: Create the MF configs\n",
    "\n",
    "Create the configs for running the Matched Filter (MF) over our ground truth sites.\n",
    "We should only have to do this once unless ground truth sites have changed.\n",
    "The MF results for these sites are stored locally in `emit_mf_gt_retrieval.nc`, which can be used for comparison in Part 2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636f84a0-ff83-4d48-8aaf-0ed4001d5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pretend that our GT sites are operator assets for our config\n",
    "mock_assets = []\n",
    "\n",
    "extent_buffer = 0.00005\n",
    "\n",
    "for idx, props in gt_sites.iterrows():\n",
    "    geom = shapely.geometry.box(\n",
    "        props.lon - extent_buffer, props.lat - extent_buffer, props.lon + extent_buffer, props.lat + extent_buffer\n",
    "    )\n",
    "\n",
    "    asset = {\n",
    "        \"asset_id\": 1000000 + idx,\n",
    "        \"name\": props.source,\n",
    "        \"lat\": props.lat,\n",
    "        \"lon\": props.lon,\n",
    "        \"geometry\": geom.wkt,\n",
    "        \"tile_id\": \"\",  # TODO do we need this?\n",
    "    }\n",
    "\n",
    "    mock_assets.append(asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "369a6080-0dbf-4e27-a940-32b758fb4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"operator_name\": \"emit_mf_for_unet_comparison\",\n",
    "    \"operator_type\": \"pilot\",\n",
    "    \"satellite_config\": {\n",
    "        \"EMIT\": {\n",
    "            \"tag\": \"0.2.18\",\n",
    "        }\n",
    "    },\n",
    "    \"runs\": mock_assets,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da06a6c3-9fef-4ec2-83bb-f8d2fe318eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"emit_mf_for_unet_comparison_mwaa.json\", \"w\") as fs:\n",
    "#     json.dump(config, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c4bef-5bfd-4b3f-b663-3b7a05bae97a",
   "metadata": {},
   "source": [
    "We now have a config for running our pipelines end-to-end, but that will end up with a lot more than we need:\n",
    "- writing lots to database\n",
    "- many artifacts in s3\n",
    "\n",
    "This is more problematic if our staging env is not fully up-and-running.\n",
    "\n",
    "We could alternatively run `satellite_data_product.emit.run` locally. For that we need to have identified the unique EMIT granules we want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee0d4479-8051-4e83-8e2e-ad1878674f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.emit_data import query_emit_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "177e8dbc-45f4-41c9-bd83-d44425971af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:24:10,834 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:11,389 - INFO - Granules found: 0\n",
      "2025-03-10 10:24:11,915 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:12,745 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:13,525 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:14,266 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:14,778 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:15,842 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:16,584 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:17,101 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:17,580 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:17,838 - INFO - Choosing EMIT_L1B_RAD_001_20240627T160707_2417911_021 out of ['EMIT_L1B_RAD_001_20240627T160655_2417911_020', 'EMIT_L1B_RAD_001_20240627T160707_2417911_021'] options\n",
      "2025-03-10 10:24:18,383 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:19,060 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:19,863 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:20,585 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:21,385 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:21,587 - INFO - Choosing EMIT_L1B_RAD_001_20240723T213247_2420514_013 out of ['EMIT_L1B_RAD_001_20240723T213247_2420514_013', 'EMIT_L1B_RAD_001_20240723T213259_2420514_014'] options\n",
      "2025-03-10 10:24:21,999 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:22,576 - INFO - Choosing EMIT_L1B_RAD_001_20240723T213259_2420514_014 out of ['EMIT_L1B_RAD_001_20240723T213247_2420514_013', 'EMIT_L1B_RAD_001_20240723T213259_2420514_014'] options\n",
      "2025-03-10 10:24:22,940 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:23,371 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:23,787 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:24,485 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:24,927 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:25,403 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:26,215 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:27,266 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:27,516 - INFO - Choosing EMIT_L1B_RAD_001_20240727T195517_2420913_016 out of ['EMIT_L1B_RAD_001_20240727T195505_2420913_015', 'EMIT_L1B_RAD_001_20240727T195517_2420913_016'] options\n",
      "2025-03-10 10:24:28,228 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:28,906 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:29,640 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:29,847 - INFO - Choosing EMIT_L1B_RAD_001_20240805T155500_2421811_015 out of ['EMIT_L1B_RAD_001_20240805T155500_2421811_015', 'EMIT_L1B_RAD_001_20240805T155512_2421811_016'] options\n",
      "2025-03-10 10:24:30,103 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:30,647 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:31,192 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:31,701 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:32,297 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:33,187 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:33,891 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:34,336 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:35,085 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:35,675 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:36,333 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:36,972 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:37,495 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:38,045 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:38,512 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:39,389 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:40,646 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:41,095 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:41,525 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:42,045 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:42,471 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:43,011 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:43,509 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:43,971 - INFO - Choosing EMIT_L1B_RAD_001_20230731T191810_2321213_013 out of ['EMIT_L1B_RAD_001_20230731T191810_2321213_013', 'EMIT_L1B_RAD_001_20230731T191822_2321213_014'] options\n",
      "2025-03-10 10:24:44,654 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:45,316 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:45,745 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:47,246 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:47,729 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:48,183 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:48,841 - INFO - Granules found: 2\n",
      "2025-03-10 10:24:49,269 - INFO - Choosing EMIT_L1B_RAD_001_20231205T165837_2333911_014 out of ['EMIT_L1B_RAD_001_20231205T165825_2333911_013', 'EMIT_L1B_RAD_001_20231205T165837_2333911_014'] options\n",
      "2025-03-10 10:24:49,487 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:50,064 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:50,563 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:51,803 - INFO - Granules found: 1\n",
      "2025-03-10 10:24:52,469 - INFO - Granules found: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 535 ms, sys: 42.4 ms, total: 578 ms\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_all_emit_ids = []\n",
    "_indices = []\n",
    "\n",
    "for idx, props in gt_sites.iterrows():\n",
    "    start_date = datetime.datetime.fromisoformat(props.date)\n",
    "    end_date = start_date + datetime.timedelta(days=1)\n",
    "    site_emit_ids = query_emit_catalog(props.lat, props.lon, start_date, end_date)\n",
    "    _all_emit_ids += site_emit_ids\n",
    "    _indices += [idx] * len(site_emit_ids)\n",
    "\n",
    "all_emit_ids = pd.DataFrame({\"site_id\": _indices, \"emit_id\": _all_emit_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "549a8f7d-24c9-455c-bc40-ad0785510f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save a copy of the mapping between sites and EMIT granules\n",
    "\n",
    "indexed_gt_sites = gt_sites.merge(all_emit_ids, left_index=True, right_on=\"site_id\", how=\"inner\")\n",
    "indexed_gt_sites = indexed_gt_sites.assign(\n",
    "    dual_index=\"siteid_\" + indexed_gt_sites.site_id.astype(str) + \"-\" + \"emitid_\" + indexed_gt_sites.emit_id\n",
    ")\n",
    "indexed_gt_sites.set_index(\"dual_index\", inplace=True)\n",
    "# indexed_gt_sites.to_csv(\"emit_gt_granule_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f18c51c-1c62-4b35-98fb-7b7dcfc38d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_emit_ids = all_emit_ids.drop_duplicates(subset=\"emit_id\")\n",
    "unique_emit_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d8b6e1-135e-4ff6-8e43-8969638a528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_run_configs = []\n",
    "\n",
    "for _, props in unique_emit_ids.iterrows():\n",
    "    gt_site = gt_sites.loc[props.site_id]\n",
    "\n",
    "    start_date = datetime.datetime.fromisoformat(gt_site.date)\n",
    "    end_date = start_date + datetime.timedelta(days=1)\n",
    "\n",
    "    geom = shapely.geometry.box(\n",
    "        gt_site.lon - extent_buffer,\n",
    "        gt_site.lat - extent_buffer,\n",
    "        gt_site.lon + extent_buffer,\n",
    "        gt_site.lat + extent_buffer,\n",
    "    )\n",
    "\n",
    "    run_config = {\n",
    "        \"run_area_name\": gt_site.source,\n",
    "        \"run_area_geometry\": geom.wkt,\n",
    "        \"tile_id\": props.emit_id,\n",
    "        \"start_date\": start_date.isoformat(),\n",
    "        \"end_date\": end_date.isoformat(),\n",
    "    }\n",
    "    individual_run_configs.append(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f61de0d-f7da-4ab9-a6f8-1273aa9ec1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"emit_mf_for_unit_comparison_local.json\", \"w\") as fs:\n",
    "#     json.dump(individual_run_configs, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d54efb-6ef5-42a8-967a-335ef2fbcda9",
   "metadata": {},
   "source": [
    "## Part 2: Crop to common extent\n",
    "\n",
    "**NOTE** run this on AWS *after* the satellite data pipelines have been run using the above configs.\n",
    "\n",
    "We want matching crops around the points of interest between U-Net and MF.\n",
    "Note that MF results will have been orthorectified but not the U-Net ones!\n",
    "\n",
    "This should also only need to be run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257464c4-d4a0-406c-bbb3-ea82f6147d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from rasterio.errors import RasterioIOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0be08-8e8e-4713-b816-ad90b28fb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_granule_map = pd.read_csv(\"emit_gt_granule_map.csv\", index_col=\"dual_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4986f17-813f-4969-9b03-1e788529849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Concatenate together crops of all ground truth locations\n",
    "\n",
    "_all_crops = []\n",
    "\n",
    "crop_size = 128\n",
    "crop_buffer = 8  # add a small buffer to account for rotations during orthorectification\n",
    "buffered_crop_size = crop_size + crop_buffer\n",
    "half_crop = buffered_crop_size // 2\n",
    "\n",
    "for dual_index, site in site_granule_map.iterrows():\n",
    "    granule_id = site[\"emit_id\"]\n",
    "    date = datetime.datetime.fromisoformat(site[\"date\"])\n",
    "\n",
    "    mf_retrieval_uri = (\n",
    "        f\"s3://orbio-scratch/emit_data/asset_data/{granule_id}/{date.year}/{date.month}/{date.day}/retrieval.tif\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        da = rioxarray.open_rasterio(mf_retrieval_uri)\n",
    "    except RasterioIOError:\n",
    "        print(f\"Cannot find granule {granule_id}. Skipping\")\n",
    "        continue\n",
    "\n",
    "    center_x = np.argmin(np.abs(da.x.values - site.lon))\n",
    "    center_y = np.argmin(np.abs(da.y.values - site.lat))\n",
    "\n",
    "    xslice = slice(center_x - half_crop, center_x + half_crop)\n",
    "    yslice = slice(center_y - half_crop, center_y + half_crop)\n",
    "\n",
    "    crop = da.isel(x=xslice, y=yslice)\n",
    "\n",
    "    # remove attributes and coords that might cause a conflict when concatenating\n",
    "    crop = crop.drop_attrs().drop_vars(\"spatial_ref\")\n",
    "\n",
    "    try:\n",
    "        # reindex our spatial dimension to a base-0 index rather than spatial coords (also to avoid\n",
    "        # conflicts when concatentating)\n",
    "        crop = crop.assign_coords(x=np.arange(buffered_crop_size), y=np.arange(buffered_crop_size))\n",
    "    except ValueError:\n",
    "        # For now just skip errors if our crop is less than complete\n",
    "        print(f\"Incomplete crop for granule {granule_id}. Skipping\")\n",
    "        continue\n",
    "\n",
    "    crop = crop.expand_dims(dual_index=[dual_index])\n",
    "\n",
    "    _all_crops.append(crop)\n",
    "\n",
    "all_crops = xr.concat(_all_crops, dim=\"dual_index\")\n",
    "del _all_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0597a68-6cb1-410f-b632-0162146d8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE only datasets can be written to NetCDF, hence why we convert it below\n",
    "# # (it would be converted automatically but with a less clear name)\n",
    "# # https://docs.xarray.dev/en/stable/generated/xarray.DataArray.to_netcdf.html#xarray.DataArray.to_netcdf\n",
    "# all_crops.to_dataset(name=\"mf_retrievals\").to_netcdf(\"emit_mf_gt_retrievals.nc\", encoding={\"mf_retrievals\": {\"zlib\": True, \"complevel\": 5}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
