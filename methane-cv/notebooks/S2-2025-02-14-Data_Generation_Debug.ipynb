{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0672f0eb-3699-48c0-aa4d-ef4f2c86f8ca",
   "metadata": {},
   "source": [
    "# Goal: Allow to run and visualize the new chip and tile selection for S2 step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 250)\n",
    "import collections\n",
    "import datetime\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import tqdm\n",
    "from pystac_client import Client\n",
    "from pathlib import Path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "import hydra\n",
    "\n",
    "import json\n",
    "from omnicloudmask import predict_from_array\n",
    "import time\n",
    "import cv2\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Polygon, box\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "from src.data.generation.base import DataGenerationConfig\n",
    "from src.data.common.sim_plumes import PlumeType\n",
    "from src.data.sentinel2 import (\n",
    "    BAND_RESOLUTIONS,\n",
    "    Sentinel2Item,\n",
    ")\n",
    "from src.data.sentinel2_l1c import Sentinel2L1CItem\n",
    "from src.data.sentinel2 import SceneClassificationLabel as SCLabel\n",
    "from src.data.azure_run_data_generation import (\n",
    "    get_queries_by_cloud_coverage,\n",
    "    get_quality_thresholds,\n",
    "    compute_transformation_combinations,\n",
    ")\n",
    "from src.data.generate import parse_quality_thresholds, SATELLITE_CLASSES\n",
    "from src.utils.parameters import SatelliteID\n",
    "from src.azure_wrap.ml_client_utils import (\n",
    "    create_ml_client_config,\n",
    "    get_abfs_output_directory,\n",
    "    get_default_blob_storage,\n",
    "    initialize_blob_service_client,\n",
    "    make_acceptable_uri,\n",
    "    get_azureml_uri,\n",
    "    initialize_ml_client,\n",
    ")\n",
    "from src.utils.git_utils import get_git_revision_hash\n",
    "\n",
    "\n",
    "def setup_logging() -> logging.Logger:\n",
    "    \"\"\"Configure root logger and with minimal Azure logging.\"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    azure_logger = logging.getLogger(\"azure\")\n",
    "    azure_logger.setLevel(logging.ERROR)\n",
    "    # Return a logger for the calling module\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65feaa-49c1-4c4b-af9d-9381aaee24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "hydra.initialize(config_path=\"../src/data/config\", version_base=None)\n",
    "config: DictConfig = hydra.compose(config_name=\"config\", overrides=[\"satellite=s2\"])\n",
    "print(f\"Satellite: {config.satellite.name}\")\n",
    "\n",
    "plume_type = PlumeType(config.plumes.plume_type)\n",
    "satellite = SatelliteID(config.satellite.id)\n",
    "\n",
    "# Get transformation combinations\n",
    "transformations_grid = OmegaConf.to_container(config.satellite_split.transformations_grid, resolve=True)\n",
    "transformations = compute_transformation_combinations(transformations_grid)  # type: ignore[arg-type]\n",
    "print(f\"Generated {len(transformations)} transformation combinations: {transformations_grid}\")\n",
    "\n",
    "# Initialize Azure ML\n",
    "ml_client = initialize_ml_client()\n",
    "\n",
    "# Set up plume catalog\n",
    "plumes_catalog_uri = get_azureml_uri(ml_client, config.plumes_split.catalog_uri)\n",
    "plume_catalog_acceptable_uri = make_acceptable_uri(str(plumes_catalog_uri))\n",
    "print(f\"Plumes catalog URI: {plumes_catalog_uri}\")\n",
    "\n",
    "suffix = \"2024_02_12_revamp_TEST\"\n",
    "\n",
    "# Set up paths and names\n",
    "out_base_dir = f\"data/{plume_type.value}/{satellite}/{config.split.name}_{suffix}\"\n",
    "experiment_name = f\"{satellite}-{plume_type.value}-{config.split.name}-{suffix}\"\n",
    "\n",
    "# Get git revision for tracking\n",
    "git_revision_hash = get_git_revision_hash()\n",
    "\n",
    "config.satellite_split.tiles_query_files = [\n",
    "    # \"../src/data/tiles/s2/csv_files/2025_05_22_MGRS_with_IDs_within_OG_val_248.csv\",\n",
    "    \"../src/data/tiles/s2/csv_files/2025_05_22_MGRS_with_IDs_within_OG_train_3413.csv\",\n",
    "]\n",
    "# Get satellite-specific queries grouped by cloud coverage\n",
    "queries_by_coverage = get_queries_by_cloud_coverage(\n",
    "    config.satellite_split.tiles_query_files,\n",
    "    config.satellite.cloud_coverage_threshold,\n",
    "    satellite,\n",
    "    config.split.name,\n",
    ")\n",
    "\n",
    "df = pd.concat([pd.read_csv(file) for file in config.satellite_split.tiles_query_files], ignore_index=True)\n",
    "print(len(df))\n",
    "df[\"month\"] = df[\"date\"].apply(lambda x: x.split(\"-\")[1])\n",
    "df[\"year\"] = df[\"date\"].apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "all_jobs = [\n",
    "    (query, transformation_params, cloud_range)\n",
    "    for cloud_range, queries in queries_by_coverage.items()\n",
    "    for query in queries\n",
    "    for transformation_params in transformations\n",
    "]\n",
    "# all_jobs\n",
    "len(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31b381-ab03-4301-a94d-b2e90bef02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_idx = np.random.randint(len(all_jobs))  # 294 = Ice\n",
    "print(job_idx)\n",
    "\n",
    "query, transformation, cloud_range = all_jobs[job_idx]\n",
    "out_dir = str(Path(out_base_dir))\n",
    "\n",
    "quality_thresholds = get_quality_thresholds(config=config, cloud_range=cloud_range, satellite=satellite)\n",
    "\n",
    "transformation_params = transformation\n",
    "\n",
    "whole_size = BAND_RESOLUTIONS[\"B11\"]\n",
    "azure_cluster = False\n",
    "test = False\n",
    "\n",
    "quality_thresholds = parse_quality_thresholds(quality_thresholds)\n",
    "print(quality_thresholds)\n",
    "\n",
    "# Validate transformation params\n",
    "assert isinstance(transformation_params, dict) and all(\n",
    "    isinstance(k, str) and isinstance(v, float) for k, v in transformation_params.items()\n",
    "), \"transformation_params must be a dictionary with each string key having one float value\"\n",
    "\n",
    "from src.utils.parameters import SATELLITE_SPATIAL_RESOLUTIONS\n",
    "\n",
    "# Create base config\n",
    "base_config = DataGenerationConfig(\n",
    "    plume_catalog=plume_catalog_acceptable_uri,\n",
    "    plume_type=plume_type,\n",
    "    out_dir=out_dir,\n",
    "    crop_size=config.crop_size,\n",
    "    quality_thresholds=quality_thresholds,\n",
    "    random_seed=config.random_seed,\n",
    "    transformation_params=transformation_params,\n",
    "    azure_cluster=azure_cluster,\n",
    "    git_revision_hash=git_revision_hash,\n",
    "    test=test,\n",
    "    ml_client=None,\n",
    "    s3_client=None,\n",
    "    storage_options=None,\n",
    "    psf_sigma=config.satellite.psf_sigma,\n",
    "    target_spatial_resolution=SATELLITE_SPATIAL_RESOLUTIONS[config.satellite.id],\n",
    "    concentration_rescale_value=config.plumes.concentration_rescale_value,\n",
    "    plume_proba_dict=config.satellite_split.plume_proba_dict,\n",
    "    hapi_data_path=config.satellite.hapi_data_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "# Run and visualize a random ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fd4a9-6cf6-4712-99ed-d61ced970bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"S2B_MSIL2A_20200721T185919_R013_T10SEJ_20200817T012938\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"mgrs\"] == \"10SEJ\") & (df[\"date\"] == \"2020-07-21\")].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d706140d-7dd4-42d8-8f48-d34e8360b41c",
   "metadata": {},
   "source": [
    "## Find main tile and reference tiles, download bands, predict cloud and cloud shadow masks with omnicloud\n",
    "- Set `visualize_tiles=True` to see the large tiles visualized + Omnicloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca6871-7575-455b-9144-6e3a96eb7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_tiles = False\n",
    "\n",
    "for k in range(1):\n",
    "    try:\n",
    "        job_idx = np.random.randint(len(all_jobs))\n",
    "        # job_idx = df[(df[\"mgrs\"] == \"10SEJ\") & (df[\"date\"] == \"2020-07-21\")].index[0]\n",
    "\n",
    "        query, transformation, cloud_range = all_jobs[job_idx]\n",
    "        sentinel_MGRS = query[\"mgrs\"]\n",
    "        sentinel_date = query[\"date\"]\n",
    "        s2_identifier = f\"{sentinel_MGRS}_{sentinel_date}\"\n",
    "        print(job_idx, s2_identifier)\n",
    "\n",
    "        quality_thresholds = parse_quality_thresholds(quality_thresholds)\n",
    "        print(f\"{quality_thresholds=}\")\n",
    "        transformation_params = transformation_params\n",
    "        print(f\"{transformation_params=}\")\n",
    "\n",
    "        sentinel_date_obj = datetime.datetime.strptime(sentinel_date, \"%Y-%m-%d\").date()\n",
    "        print(sentinel_date_obj)\n",
    "\n",
    "        # Create transformation-cloud_coverage-specific output directory\n",
    "        out_dir = str(Path(out_base_dir))  # / transform_str / cloud_bucket_str)\n",
    "\n",
    "        # Get satellite-specific class and parameters\n",
    "        SatelliteClass = SATELLITE_CLASSES[satellite]\n",
    "        bands = config.satellite.bands\n",
    "        if \",\" in bands:\n",
    "            bands = bands.split(\",\")\n",
    "        satellite_params = {\n",
    "            \"sentinel_MGRS\": sentinel_MGRS,\n",
    "            \"sentinel_date\": sentinel_date_obj,\n",
    "            \"bands\": bands,\n",
    "            \"time_delta_days\": config.satellite.time_delta_days,\n",
    "            \"nb_reference_ids\": config.satellite.nb_reference_ids,\n",
    "            \"omnicloud_cloud_t\": config.satellite.omnicloud_cloud_t,\n",
    "            \"omnicloud_shadow_t\": config.satellite.omnicloud_shadow_t,\n",
    "            # \"reference_chip_max_bad_px_perc\": config.satellite.reference_chip_max_bad_px_perc,\n",
    "        }\n",
    "        # Try 10 or 25\n",
    "        nb_reference_ids = 10\n",
    "        # Create and run pipeline\n",
    "        pipeline = SatelliteClass(**satellite_params, **base_config.model_dump())\n",
    "        pipeline.nb_reference_ids = nb_reference_ids\n",
    "\n",
    "        pipeline.visualize_tiles = visualize_tiles\n",
    "        data = pipeline.download_data()\n",
    "        break\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        import traceback\n",
    "\n",
    "        print(traceback.print_exception(None, err, err.__traceback__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7058c-62a2-4d5b-b9cb-ef516f08a643",
   "metadata": {},
   "source": [
    "## Visualize chipping\n",
    "- Setting `pipeline.visualize_crops=True` and `pipeline.visualize_crops_show_frac = 0.05` will visualize 5% of the created chips\n",
    "- Setting `pipeline.visualize_insertion=True` will visualize the insertion of methane of the created chips\n",
    "- Running the next cell with `pipeline.visualize_crops=False` and `pipeline.visualize_insertion=False` will create all chips and print the report at the end of what happened. The output dataframe is saved to \"test.parquet\". A report with some stats of what happened is saved at \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210fa08-19b1-43c1-be2b-7bf2b4aa4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Crop counts\n",
    "pipeline.non_overlapping_count = 0\n",
    "pipeline.overlapping_count = 0\n",
    "pipeline.too_much_main_nodata_count = 0\n",
    "pipeline.succeed_5perc_count = 0\n",
    "pipeline.failed_5perc_count = 0\n",
    "pipeline.reference_indices_all = []\n",
    "\n",
    "pipeline.visualize_crops = False\n",
    "pipeline.visualize_crops_show_frac = 0.05\n",
    "pipeline.visualize_insertion = False\n",
    "crops = pipeline.generate_crops(data)\n",
    "\n",
    "data_items = pipeline.generate_synthetic_data_items(pipeline.plume_files, crops)\n",
    "\n",
    "local_parquet_path = pipeline.save_parquet(data_items, save_cloud=False, save_local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc701fe-1283-4d09-96aa-9e9e45994814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"test.parquet\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56644ba2-18ad-407f-a6bb-c01da6fa29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\", \"rb\") as f:\n",
    "    json_data = f.read()  # Read as bytes\n",
    "json_data = json.loads(json_data.decode(\"utf-8\"))\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eef928-5f3d-4713-b66b-7a1faa16814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns[:50], df.columns[50:100], df.columns[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd149403-ca60-4030-b098-5860d726746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"exclusion_perc\",\n",
    "        \"chip_cloud_combined_perc_main\",\n",
    "        \"chip_cloud_shadow_omni_perc_main\",\n",
    "        \"how_many_plumes_we_wanted\",\n",
    "        \"how_many_plumes_we_inserted\",\n",
    "        \"tile_SCL_SNOW_perc_main\",\n",
    "    ]\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f90f9c-cd37-4a60-984a-c4659e5d0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"exclusion_perc\",\n",
    "        \"chip_cloud_combined_perc_main\",\n",
    "        \"chip_cloud_shadow_omni_perc_main\",\n",
    "        \"tile_cloud_omni_perc_main\",\n",
    "        \"tile_cloud_combined_perc_main\",\n",
    "        \"tile_cloud_shadow_omni_perc_main\",\n",
    "        \"tile_cloud_shadow_combined_perc_main\",\n",
    "        \"tile_no_data_perc_main\",\n",
    "    ]\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79909d66-a1b1-452f-aa72-2f7bb3aece54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"plume_files\",\n",
    "        \"plume_sizes\",\n",
    "        \"how_many_plumes_we_wanted\",\n",
    "        \"how_many_plumes_we_inserted\",\n",
    "        \"plumes_inserted_idxs\",\n",
    "        \"plume_emissions\",\n",
    "        \"frac_abs_sum\",\n",
    "        \"bands\",\n",
    "        \"size\",\n",
    "        \"crop_x\",\n",
    "        \"crop_y\",\n",
    "        \"main_and_reference_ids\",\n",
    "        \"main_and_reference_dates\",\n",
    "    ]\n",
    "].sample(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
