{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1718719488166
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import torch\n",
    "from azureml.fsspec import AzureMachineLearningFileSystem\n",
    "from torch import nn\n",
    "\n",
    "from src.azure_wrap.blob_storage_sdk_v2 import DATASTORE_URI\n",
    "from src.training.loss_functions import TwoPartLoss\n",
    "from src.training.transformations import ConcatenateSnapshots\n",
    "from src.utils.parameters import MAIN_BANDS, S2_BANDS, SNAPSHOTS, TEMPORAL_BANDS, SatelliteID\n",
    "from src.validation.metrics import FalseMetrics, TrueMetrics\n",
    "from src.validation.validation_metrics import (\n",
    "    all_error_analysis_plots,\n",
    "    data_preparation,\n",
    "    diff_plots,\n",
    "    prep_predictions_for_plot,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Load the run parameters and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1718719490145
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# the run ID (job name) can be copy-pasted from the job's page in the Azure ML studio\n",
    "run_id = \"mango_chaconia_xshmtkk1yx\"\n",
    "\n",
    "# get the runs parameters\n",
    "run = mlflow.get_run(run_id=run_id)\n",
    "params = run.data.params\n",
    "\n",
    "BINARY_THRESHOLD = float(params[\"binary_threshold\"])\n",
    "MSE_MULTIPLIER = float(params[\"MSE_multiplier\"])\n",
    "model_identifier = params[\"model_name\"]\n",
    "# note, the validation dataset (and training / test) aren't the actual URIs to the data\n",
    "# since we have AML download the data to disk the paths get converted to a local path\n",
    "# we can get the actual paths from the training config if needed.\n",
    "validation_datasets = [params[x] for x in params.keys() if \"validation_dataset\" in x]\n",
    "\n",
    "# grab the parent folder from the first dataset so we can glob all the validation data\n",
    "validation_uri = Path(validation_datasets[0]).parent.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1718722224280
    }
   },
   "outputs": [],
   "source": [
    "# Download run metrics into a temporary directory so we can load into memory\n",
    "with tempfile.TemporaryDirectory() as dst_path:\n",
    "    mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=\"metrics_per_crop.parquet\", dst_path=dst_path)\n",
    "    metrics_df = pd.read_parquet(os.path.join(dst_path, \"metrics_per_crop.parquet\"))\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFn = TwoPartLoss(binary_threshold=BINARY_THRESHOLD, MSE_multiplier=MSE_MULTIPLIER)\n",
    "band_concatenator = ConcatenateSnapshots(\n",
    "    snapshots=SNAPSHOTS,\n",
    "    s2_bands=S2_BANDS,\n",
    "    temporal_bands=TEMPORAL_BANDS,\n",
    "    main_bands=MAIN_BANDS,\n",
    "    satellite_id=SatelliteID.S2,\n",
    ")\n",
    "fs = AzureMachineLearningFileSystem(DATASTORE_URI)\n",
    "\n",
    "validation_dataset = data_preparation(validation_uri, band_concatenator=band_concatenator, filesystem=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1717766686228
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load and prep model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = mlflow.pytorch.load_model(model_identifier, map_location=device)\n",
    "if isinstance(model, nn.DataParallel):\n",
    "    model = model.module  # if it's wrapped in DataParallel, unwrap it\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Possible metrics to sort by\")\n",
    "list([k.value for k in TrueMetrics] + [k.value for k in FalseMetrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plots come crops (chips)\n",
    "num_worst_crops = 10\n",
    "probability_threshold = 0.25\n",
    "sorting_metric = \"false_negatives\"\n",
    "ascending = sorting_metric not in set(FalseMetrics)\n",
    "metrics_df = metrics_df.sort_values(by=sorting_metric, ascending=ascending)\n",
    "\n",
    "for i in range(num_worst_crops):\n",
    "    crop = metrics_df.iloc[i]\n",
    "    index = (crop.partition, crop.row)\n",
    "    pred = prep_predictions_for_plot(model, validation_dataset.dataset, index, lossFn, probability_threshold)\n",
    "    fig = all_error_analysis_plots(probability_threshold=probability_threshold, **pred)\n",
    "    fig_simple = diff_plots(probability_threshold=probability_threshold, **pred)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "methane-cv"
  },
  "kernelspec": {
   "display_name": "methane-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
