{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Mass product SBR phase 1 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "from lib.models.schemas import WatershedParameters\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sbr_2025.utils.quantification import (\n",
    "    get_wind_components,\n",
    "    sbr_form_outputs,\n",
    ")\n",
    "from src.azure_wrap.ml_client_utils import initialize_blob_service_client\n",
    "from src.inference.inference_functions import (\n",
    "    crop_main_data_landsat,\n",
    "    crop_reference_data_landsat,\n",
    "    fetch_landsat_items_for_point,\n",
    "    query_landsat_catalog_for_point,\n",
    ")\n",
    "from src.training.loss_functions import TwoPartLoss\n",
    "from src.utils.parameters import LANDSAT_HAPI_DATA_PATH, SatelliteID\n",
    "from src.utils.quantification_utils import calc_effective_wind_speed, calc_wind_direction\n",
    "from src.utils.radtran_utils import RadTranLookupTable\n",
    "from src.utils.utils import initialize_clients, load_model_and_concatenator\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "ðŸ””ðŸ””ðŸ””ðŸ””\n",
    "\n",
    "**HOW TO UPDATE THIS NOTEBOOK**\n",
    "\n",
    "This is a template notebook that is under version control.\n",
    "When making changes, before staging and committing the changes, run `nbstripout` to remove the output from the notebook.\n",
    "\n",
    "```bash\n",
    "# conda install -c conda-forge nbstripout  # install nbstripout if not already installed\n",
    "nbstripout --drop-empty-cells --extra-keys=\"metadata.kernelspec.display_name metadata.kernelspec.name\" Landsat_SBR_export_results.ipynb\n",
    "git add -p Landsat_SBR_export_results.ipynb\n",
    "```\n",
    "\n",
    "ðŸ””ðŸ””ðŸ””ðŸ””"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client, _, _, s3_client = initialize_clients(False)\n",
    "abs_client = initialize_blob_service_client(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 32.82175, -111.78581  # release point for SBRs\n",
    "\n",
    "# can we predict on larger chips?\n",
    "crop_size = 256  # 128\n",
    "center_buffer = 3  # 12  # 5  # number of pixels to search from center\n",
    "\n",
    "# Date range of SBRs\n",
    "start_date = \"2025-01-01\"\n",
    "end_date = \"2025-04-30\"  # a month after the end of the SBRs to include reference images after\n",
    "\n",
    "# these dates have KNOWN releases during Phase 0\n",
    "phase0_release_dates = [\n",
    "    # \"2024-11-14\",\n",
    "    \"2024-11-15\",  # LS\n",
    "    \"2024-11-16\",  # LS\n",
    "    # \"2024-11-19\",\n",
    "    # \"2024-11-22\",\n",
    "    \"2024-11-24\",  # LS\n",
    "    \"2024-12-02\",  # LS\n",
    "    # \"2024-12-04\",\n",
    "    # \"2024-12-07\",\n",
    "    \"2024-12-09\",  # LS\n",
    "    # \"2024-12-17\",\n",
    "    # \"2024-12-19\",\n",
    "    # \"2024-12-22\",\n",
    "    \"2024-12-26\",  # LS\n",
    "    # \"2024-12-29\",\n",
    "]\n",
    "\n",
    "release_dates_2022 = [\n",
    "    \"2022-10-25\",\n",
    "    \"2022-10-26\",\n",
    "    \"2022-11-02\",\n",
    "    \"2022-11-03\",\n",
    "    \"2022-11-10\",\n",
    "    \"2022-11-11\",\n",
    "    \"2022-11-18\",\n",
    "]\n",
    "\n",
    "watershed_params = WatershedParameters(\n",
    "    marker_distance=1,\n",
    "    marker_threshold=0.1,\n",
    "    watershed_floor_threshold=0.075,\n",
    "    closing_footprint_size=0,\n",
    ")\n",
    "item_meta_dict = {}\n",
    "\n",
    "start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(end_date, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ids = [\"37\", \"155\", \"55\", \"57\", \"103\", \"168\", \"154\", \"14\"]\n",
    "models = []\n",
    "band_concatenators = []\n",
    "for model_id in model_ids:\n",
    "    model, band_concatenator, train_params = load_model_and_concatenator(\n",
    "        f\"models:/landsat/{model_id}\", device, SatelliteID.LANDSAT\n",
    "    )\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "    band_concatenators.append(band_concatenator)\n",
    "\n",
    "lossFn = TwoPartLoss(train_params[\"binary_threshold\"], train_params[\"MSE_multiplier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_items = query_landsat_catalog_for_point(lat, lon, start_date, end_date)\n",
    "for item in stac_items:\n",
    "    cloud_cover = item.properties[\"eo:cloud_cover\"]\n",
    "    print(\n",
    "        f\"{item.datetime.date().isoformat()} with {cloud_cover:6.1f}% clouds - ({item.id})\"\n",
    "        f\"and CRS {item.properties['proj:code']}\"\n",
    "    )\n",
    "overpass_dates = [item.datetime.date().isoformat() for item in stac_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "target_date = stac_items[-1].datetime.date().isoformat()\n",
    "target_date = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "\n",
    "items = fetch_landsat_items_for_point(lat=lat, lon=lon, query_datetime=target_date, how_many_days_back=180)\n",
    "\n",
    "main_data = crop_main_data_landsat(items, abs_client, s3_client, lat, lon, crop_size)\n",
    "main_item = main_data[\"tile_item\"]\n",
    "\n",
    "# Use 25% clouds/shadows cutoff to include non-obvious reference images that may help\n",
    "max_bad_pixel_perc = 25  # max % sum of clouds/cloud shadows/nodata in reference chips\n",
    "num_snapshots = 40\n",
    "\n",
    "for item in tqdm(items):\n",
    "    if item.id not in item_meta_dict:\n",
    "        # Get the Landsat metadata from the coastal band (arbitrary choice).\n",
    "        try:\n",
    "            item_meta_dict[item.id] = item.get_raster_meta(\"coastal\", abs_client=abs_client)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "all_reference_data = crop_reference_data_landsat(\n",
    "    items,\n",
    "    main_data,\n",
    "    abs_client,\n",
    "    s3_client,\n",
    "    lat,\n",
    "    lon,\n",
    "    crop_size,\n",
    "    required_num_previous_snapshots=num_snapshots,\n",
    "    max_bad_pixel_perc=max_bad_pixel_perc,\n",
    "    item_meta_dict=item_meta_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare wind data once\n",
    "wind_data = pd.read_csv(\"../../src/data/ancillary/wind_vectors_gt_vs_models_2025_sbr_sites.csv\")\n",
    "wind_data = wind_data[wind_data[\"sensor\"] == \"LS\"]\n",
    "wind_data[\"sensing_time\"] = pd.to_datetime(\n",
    "    wind_data[\"date\"] + \" \" + wind_data[\"overpass_time_utc\"], utc=True\n",
    ").dt.strftime(\"%Y-%m-%dT%H:%M:%S+0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./landsat_phase1_decision_dict.json\") as fs:\n",
    "    decisions_dict = json.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_distance_pixels = 10\n",
    "pixel_width = 30\n",
    "\n",
    "with io.StringIO() as fs:\n",
    "    results_index = []\n",
    "    for stac_idx, stac_item in enumerate(items):\n",
    "        target_date = stac_item.time.date().isoformat()\n",
    "        _target_date = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "        print(f\"Running for date {target_date}\")\n",
    "        if target_date not in decisions_dict:\n",
    "            print(\"    Not present in decisions dict!\")\n",
    "            print(\"=\" * 100)\n",
    "            continue\n",
    "\n",
    "        # Load main_data\n",
    "        main_data = crop_main_data_landsat(items, abs_client, s3_client, lat, lon, crop_size, main_idx=stac_idx)\n",
    "        main_item = main_data[\"tile_item\"]\n",
    "        sensing_time = main_item.time.isoformat()\n",
    "\n",
    "        # Get wind speed for observation\n",
    "        sensing_time = main_item.time.isoformat()\n",
    "        wind_components = get_wind_components(wind_data, sensing_time)\n",
    "        u_wind_component, v_wind_component = wind_components[\"geos\"]\n",
    "        wind_speed_geos = calc_effective_wind_speed(u_wind_component, v_wind_component)\n",
    "        wind_direction_geos = calc_wind_direction(u_wind_component, v_wind_component)\n",
    "        u_wind_component, v_wind_component = wind_components[\"era5\"]\n",
    "        wind_speed_era5 = calc_effective_wind_speed(u_wind_component, v_wind_component)\n",
    "        wind_direction_era5 = calc_wind_direction(u_wind_component, v_wind_component)\n",
    "\n",
    "        # Get correct lookup table\n",
    "        lookup_table = RadTranLookupTable.from_params(\n",
    "            instrument=main_item.instrument,\n",
    "            solar_angle=main_item.solar_angle,\n",
    "            observation_angle=main_item.observation_angle,\n",
    "            hapi_data_path=LANDSAT_HAPI_DATA_PATH,\n",
    "            min_ch4=0.0,\n",
    "            max_ch4=21.0,  # this value was selected based on the common value ranges of the sim plume datasets\n",
    "            spacing_resolution=40000,\n",
    "            ref_band=main_item.swir16_band_name,\n",
    "            band=main_item.swir22_band_name,\n",
    "            full_sensor_name=main_item.sensor_name,\n",
    "        )\n",
    "\n",
    "        csv_row = sbr_form_outputs(\n",
    "            decisions_dict[target_date],\n",
    "            wind_speed_geos,\n",
    "            wind_direction_geos,\n",
    "            wind_speed_era5,\n",
    "            wind_direction_era5,\n",
    "            model_ids,\n",
    "            models,\n",
    "            device,\n",
    "            band_concatenators,\n",
    "            main_data,\n",
    "            all_reference_data,\n",
    "            lossFn,\n",
    "            lookup_table,\n",
    "            max_distance_pixels,\n",
    "            pixel_width,\n",
    "            main_item,\n",
    "            _target_date,\n",
    "            SatelliteID.LANDSAT,\n",
    "            abs_client,\n",
    "        )\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        fs.write(csv_row)\n",
    "        results_index.append(target_date)\n",
    "\n",
    "    fs.seek(0)\n",
    "    results = pd.read_csv(fs, header=None)\n",
    "    results[\"date\"] = results_index\n",
    "    results.set_index(\"date\", inplace=True)\n",
    "    results.columns = [\n",
    "        \"PlumeLength\",\n",
    "        \"IME\",\n",
    "        \"EmissionRate\",\n",
    "        \"EmissionRateUpper\",\n",
    "        \"EmissionRateLower\",\n",
    "        \"EmissionRateUncertaintyType\",\n",
    "        \"U10WindSpeed\",\n",
    "        \"UeffWindSpeed\",\n",
    "        \"WindSpeedUpper\",\n",
    "        \"WindSpeedLower\",\n",
    "        \"WindSpeedUncertaintyType\",\n",
    "        \"WindDirection\",\n",
    "        \"notes\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_datestr = \"2025-03-23\"  # only required if we are plotting single\n",
    "version = \"04302025\"  # The date on which the images were produced\n",
    "\n",
    "print(f\"CAUTION: showing images produced on {version}\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# loop and plot all\n",
    "for inspect_datestr in sorted([*decisions_dict.keys()]):\n",
    "    # print(decisions_dict[inspect_datestr])\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    detection_note = decisions_dict[inspect_datestr][\"note\"]\n",
    "    feasibility = \"feasible\" if decisions_dict[inspect_datestr][\"feasible\"] else \"infeasible\"\n",
    "    fig.suptitle(f\"Landsat result for {inspect_datestr}: {detection_note} ({feasibility})\")\n",
    "\n",
    "    with rasterio.open(\n",
    "        f\"data/submission_geotiffs/phase1_submission/LANDSAT/DateGenerated{version}_{inspect_datestr}_LANDSAT_OrbioEarth_Enhancement.tif\"\n",
    "    ) as reader:\n",
    "        ax = plt.subplot(131)\n",
    "        data = reader.read(1)\n",
    "        im = ax.imshow(\n",
    "            data,\n",
    "            interpolation=\"none\",\n",
    "            vmin=1,\n",
    "            vmax=150 if data.max() < 150 else 1500,  # noqa: PLR2004\n",
    "            # norm=\"log\",\n",
    "            cmap=\"Reds\",\n",
    "        )\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        ax.set_title(\"Retrieval (lin)\")\n",
    "\n",
    "        ax = plt.subplot(132)\n",
    "        im = ax.imshow(\n",
    "            reader.read(1) + 1,\n",
    "            interpolation=\"none\",\n",
    "            vmin=1,\n",
    "            vmax=1500,\n",
    "            norm=\"log\",\n",
    "            cmap=\"Reds\",\n",
    "        )\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        ax.set_title(\"Retrieval (log)\")\n",
    "\n",
    "    ax = plt.subplot(133)\n",
    "    with rasterio.open(\n",
    "        f\"data/submission_geotiffs/phase1_submission/LANDSAT/DateGenerated{version}_{inspect_datestr}_LANDSAT_OrbioEarth_Mask.tif\"\n",
    "    ) as reader:\n",
    "        ax.imshow(reader.read(1), interpolation=\"none\", vmin=0, vmax=1, cmap=\"Greys\")\n",
    "        ax.set_title(\"Mask\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
