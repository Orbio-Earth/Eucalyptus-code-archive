{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "from lib.models.schemas import WatershedParameters\n",
    "from rasterio.crs import CRS\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sbr_2025 import BANDS\n",
    "from sbr_2025.utils import intersects_center, select_reference_tiles_from_dates_str\n",
    "from sbr_2025.utils.plotting import (\n",
    "    Colorbar,\n",
    "    all_error_analysis_plots,\n",
    "    get_band_ratio,\n",
    "    get_rgb_bands,\n",
    "    plot_all_ratio,\n",
    "    plot_all_rgb,\n",
    "    plot_max_proba_center_buffer_heatmap,\n",
    "    plot_normal_and_avg_strategy,\n",
    "    plot_normal_and_avg_strategy_summary,\n",
    "    plot_ratio_diffs,\n",
    "    plot_rgb_ratio,\n",
    "    plot_wind,\n",
    "    validate_pred_retrievals,\n",
    ")\n",
    "from sbr_2025.utils.prediction import (\n",
    "    PlumeInfo,\n",
    "    TileInfo,\n",
    "    export_predition_and_mask_to_geotiff,\n",
    "    get_center_buffer,\n",
    "    get_reference_data,\n",
    "    predict,\n",
    "    predict_for_all_pairs,\n",
    ")\n",
    "from sbr_2025.utils.quantification import (\n",
    "    get_wind_components,\n",
    "    sbr_form_outputs,\n",
    ")\n",
    "from src.azure_wrap.ml_client_utils import initialize_blob_service_client\n",
    "from src.data.landsat_data import LandsatGranuleAccess\n",
    "from src.data.sentinel2 import Sentinel2Item\n",
    "from src.inference.inference_functions import (\n",
    "    crop_main_data,\n",
    "    crop_reference_data,\n",
    "    fetch_sentinel2_items_for_point,\n",
    "    query_sentinel2_catalog_for_point,\n",
    ")\n",
    "from src.inference.inference_target_location import (\n",
    "    quantify_retrieval,\n",
    ")\n",
    "from src.plotting.plotting_functions import grid16\n",
    "from src.training.loss_functions import TwoPartLoss\n",
    "from src.utils.parameters import LANDSAT_HAPI_DATA_PATH, S2_HAPI_DATA_PATH, SatelliteID\n",
    "from src.utils.quantification_utils import calc_effective_wind_speed, calc_wind_direction\n",
    "from src.utils.radtran_utils import RadTranLookupTable\n",
    "from src.utils.utils import initialize_clients, load_model_and_concatenator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "ðŸ””ðŸ””ðŸ””ðŸ””\n",
    "\n",
    "**HOW TO UPDATE THIS NOTEBOOK**\n",
    "\n",
    "This is a template notebook that is under version control.\n",
    "When making changes, before staging and committing the changes, run `nbstripout` to remove the output from the notebook.\n",
    "\n",
    "```bash\n",
    "# conda install -c conda-forge nbstripout  # install nbstripout if not already installed\n",
    "nbstripout --drop-empty-cells --extra-keys=\"metadata.kernelspec.display_name metadata.kernelspec.name\" S2_SBR_exploration.ipynb\n",
    "git add -p S2_SBR_exploration.ipynb\n",
    "```\n",
    "\n",
    "ðŸ””ðŸ””ðŸ””ðŸ””"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client, _, _, _, s3_client = initialize_clients(False)\n",
    "abs_client = initialize_blob_service_client(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 32.82175, -111.78581  # release point for SBRs\n",
    "\n",
    "# can we predict on larger chips?\n",
    "crop_size = 256\n",
    "center_buffer = 5  # number of pixels to search from center\n",
    "\n",
    "# Date range of SBR Phase 1\n",
    "start_date = \"2024-10-01\"\n",
    "# end_date = \"2025-03-31\"\n",
    "end_date = \"2025-04-30\"  # a month after the end of the SBRs to include reference images after\n",
    "\n",
    "# these dates have KNOWN releases during Phase 0\n",
    "phase0_release_dates = [\n",
    "    \"2024-11-14\",\n",
    "    \"2024-11-19\",\n",
    "    \"2024-11-22\",\n",
    "    \"2024-12-02\",\n",
    "    \"2024-12-04\",\n",
    "    \"2024-12-07\",\n",
    "    \"2024-12-09\",\n",
    "    \"2024-12-17\",\n",
    "    \"2024-12-19\",\n",
    "    \"2024-12-22\",\n",
    "    \"2024-12-29\",\n",
    "]\n",
    "\n",
    "watershed_params = WatershedParameters(\n",
    "    marker_distance=1,\n",
    "    marker_threshold=0.1,\n",
    "    watershed_floor_threshold=0.075,\n",
    "    closing_footprint_size=0,\n",
    ")\n",
    "item_meta_dict = {}\n",
    "\n",
    "start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(end_date, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Models\n",
    "- 1226: Production model\n",
    "  - mAvgRecall: 44.6% (Hassi: 77.2%, Marcellus: 11.2%, Permian: 45.4%)\n",
    "- 1475: b3 encoder\n",
    "  - mAvgRecall: 46.4% (Hassi: 78.9%, Marcellus: 11.9%, Permian: 48.4%)\n",
    "- 1486: b4 encoder\n",
    "  - mAvgRecall: 45.9% (Hassi: 77.9%, Marcellus: 11.9%, Permian: 47.8%)\n",
    "- 1395: Only deserts model, Hassi val\n",
    "  - Hassi: 77.3%\n",
    "- 1422: Weight Decay = 0\n",
    "  - mAvgRecall: 44.1% (Hassi: 77.2%, Marcellus: 10.2%, Permian: 45.0%)\n",
    "- 1340: Dropping hardest ~10% parquets\n",
    "  - mAvgRecall: 44.1% (Hassi: 76.5%, Marcellus: 10.5%, Permian: 45.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ids = [\"1226\", \"1475\", \"1486\", \"1395\", \"1422\", \"1340\"]\n",
    "models = []\n",
    "band_concatenators = []\n",
    "for model_id in model_ids:\n",
    "    model, band_concatenator, train_params = load_model_and_concatenator(\n",
    "        f\"models:/torchgeo_pwr_unet/{model_id}\", device, SatelliteID.S2\n",
    "    )\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "    band_concatenators.append(band_concatenator)\n",
    "\n",
    "lossFn = TwoPartLoss(train_params[\"binary_threshold\"], train_params[\"MSE_multiplier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Overpass Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_items = query_sentinel2_catalog_for_point(lat, lon, start_date, end_date, crop_size, sbr_notebook=True)\n",
    "\n",
    "for item in stac_items:\n",
    "    print(f\"{item.datetime.isoformat(timespec='seconds')} - {item.id}\")\n",
    "\n",
    "overpass_dates = [item.datetime.date().isoformat() for item in stac_items]\n",
    "overpass_times = [item.datetime.time().isoformat(timespec=\"seconds\") for item in stac_items]\n",
    "\n",
    "# the following are printed in a format for easier copying into spreadsheets\n",
    "# for d in overpass_dates:\n",
    "#     print(d)\n",
    "# for t in overpass_times:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates to avoid using for reference tiles: cloudy / emission\n",
    "bad_reference_dates = {\n",
    "    \"2025-01-06\": [\"clouds\"],\n",
    "    \"2025-01-08\": [\"clouds\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# choose a single date to do inference\n",
    "target_date = overpass_dates[-1]\n",
    "target_date = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "\n",
    "number_of_days = (end_date - start_date).days + 10\n",
    "items_for_entire_phase = fetch_sentinel2_items_for_point(\n",
    "    lat=lat,\n",
    "    lon=lon,\n",
    "    query_datetime=target_date,\n",
    "    crop_size=crop_size,\n",
    "    how_many_days_back=number_of_days,\n",
    "    sbr_notebook=True,\n",
    ")\n",
    "\n",
    "main_data = crop_main_data(items_for_entire_phase, abs_client, s3_client, lat, lon, crop_size)\n",
    "main_item = main_data[\"tile_item\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items_for_entire_phase:\n",
    "    print(item.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Tile info for all overpasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_properties = TileInfo(\n",
    "    instrument_name=main_item.item.properties[\"platform\"],\n",
    "    date_analysis=datetime.today().date().isoformat(),\n",
    "    observation_date=main_item.time.date().isoformat(),\n",
    "    observation_timestamp=main_item.time.time().isoformat(timespec=\"seconds\"),\n",
    "    start_time=None,\n",
    "    end_time=None,\n",
    "    imaging_mode=main_item.imaging_mode,\n",
    "    off_nadir_angle=main_item.off_nadir_angle,\n",
    "    viewing_azimuth=main_item.viewing_azimuth,\n",
    "    solar_zenith=main_item.solar_zenith,\n",
    "    solar_azimuth=main_item.solar_azimuth,\n",
    "    orbit_state=main_item.orbit_state,\n",
    ")\n",
    "\n",
    "pprint.pp(tile_properties)\n",
    "tile_properties.asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_infos = []\n",
    "for t in tqdm(overpass_dates):\n",
    "    # print(f\"Date: {t}\")\n",
    "    date = datetime.strptime(t, \"%Y-%m-%d\")\n",
    "\n",
    "    items_for_tile_info = fetch_sentinel2_items_for_point(\n",
    "        lat=lat, lon=lon, query_datetime=date, crop_size=crop_size, sbr_notebook=True\n",
    "    )\n",
    "\n",
    "    main_data = crop_main_data(items_for_tile_info, abs_client, s3_client, lat, lon, crop_size)\n",
    "    main_item = main_data[\"tile_item\"]\n",
    "\n",
    "    tile_properties = TileInfo(\n",
    "        instrument_name=main_item.item.properties[\"platform\"],\n",
    "        date_analysis=datetime.today().date().isoformat(),\n",
    "        observation_date=main_item.time.date().isoformat(),\n",
    "        observation_timestamp=main_item.time.time().isoformat(timespec=\"seconds\"),\n",
    "        start_time=None,\n",
    "        end_time=None,\n",
    "        imaging_mode=main_item.imaging_mode,\n",
    "        off_nadir_angle=main_item.off_nadir_angle,\n",
    "        viewing_azimuth=main_item.viewing_azimuth,\n",
    "        solar_zenith=main_item.solar_zenith,\n",
    "        solar_azimuth=main_item.solar_azimuth,\n",
    "        orbit_state=main_item.orbit_state,\n",
    "    )\n",
    "\n",
    "    tile_infos.append(tile_properties.asdict())\n",
    "\n",
    "df = pd.DataFrame(tile_infos, index=overpass_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(df.solar_azimuth):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Load in Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 25% clouds/shadows cutoff to include non-obvious reference images that may help\n",
    "max_bad_pixel_perc = 25  # max % sum of clouds/cloud shadows/nodata in reference chips\n",
    "num_snapshots = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all dates in items_for_entire_phase:\n",
    "for item in items_for_entire_phase:\n",
    "    print(item.item.datetime.date().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data = crop_reference_data(\n",
    "    items_for_entire_phase,\n",
    "    main_data,\n",
    "    abs_client,\n",
    "    s3_client,\n",
    "    lat,\n",
    "    lon,\n",
    "    crop_size,\n",
    "    required_num_previous_snapshots=1000000,  # want all the reference images\n",
    "    max_bad_pixel_perc=max_bad_pixel_perc,\n",
    ")\n",
    "\n",
    "print(\"\\n---: Summary\")\n",
    "print(f\"Main tile for {target_date}: USE {main_item.id}\")\n",
    "for reference in reference_data:\n",
    "    tile_id = reference[\"tile_item\"].id\n",
    "    reference_date = reference[\"tile_item\"].time.date().isoformat()\n",
    "    print(f\"    Reference tile on {reference_date}: USE {tile_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## I. RGBs & Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show all of them together\n",
    "plot_all_rgb([main_data, *reference_data], SatelliteID.S2)\n",
    "plot_all_ratio([main_data, *reference_data], SatelliteID.S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show them individually\n",
    "data_items = [main_data, *reference_data]\n",
    "\n",
    "for i, data in enumerate(data_items):\n",
    "    date = data[\"tile_item\"].time.date().isoformat()\n",
    "    plot_rgb_ratio(data, Colorbar.INDIVIDUAL, i, SatelliteID.S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ratio Diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_ratio_diffs(data_items, Colorbar.INDIVIDUAL, SatelliteID.S2, mean_adjust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## II. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Predict for a specific date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### Select Reference Chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reference tile dates:\")\n",
    "for x in reference_data:\n",
    "    reference_date = x[\"tile_item\"].time.date().isoformat()\n",
    "    if reference_date in overpass_dates:\n",
    "        print(f\"{reference_date} - possible SBR release (date is in Phase 1)\")\n",
    "    elif reference_date in phase0_release_dates:\n",
    "        print(f\"{reference_date} - known SBR release (date is in Phase 0)\")\n",
    "    else:\n",
    "        print(f\"{reference_date} - not a Phase 1 overpass date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"1226\"\n",
    "model_idx = model_id.index(model_id)\n",
    "\n",
    "before_date = \"2025-03-29T17:59:09.024000+00:00\"  # \"2025-03-29\"\n",
    "earlier_date = \"2025-03-27T18:10:11.025000+00:00\"  # \"2025-03-27\"\n",
    "\n",
    "reference_chips = select_reference_tiles_from_dates_str(\n",
    "    reference_data, before_date=before_date, earlier_date=earlier_date\n",
    ")\n",
    "before_data = reference_chips[0]\n",
    "earlier_data = reference_chips[1]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"tile\": [\"main\", \"before\", \"earlier\"],\n",
    "        \"date\": [\n",
    "            main_data[\"tile_item\"].time.date().isoformat(),\n",
    "            before_data[\"tile_item\"].time.date().isoformat(),\n",
    "            earlier_data[\"tile_item\"].time.date().isoformat(),\n",
    "        ],\n",
    "        \"time\": [\n",
    "            main_data[\"tile_item\"].time.time().isoformat(),\n",
    "            before_data[\"tile_item\"].time.time().isoformat(),\n",
    "            earlier_data[\"tile_item\"].time.time().isoformat(),\n",
    "        ],\n",
    "        \"datetime\": [main_data[\"tile_item\"].time, before_data[\"tile_item\"].time, earlier_data[\"tile_item\"].time],\n",
    "        \"observation_angle\": [\n",
    "            main_data[\"tile_item\"].observation_angle,\n",
    "            before_data[\"tile_item\"].observation_angle,\n",
    "            earlier_data[\"tile_item\"].observation_angle,\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "watershed_params = WatershedParameters(\n",
    "    marker_distance=1,\n",
    "    marker_threshold=0.1,\n",
    "    watershed_floor_threshold=0.075,\n",
    "    closing_footprint_size=0,\n",
    ")\n",
    "prediction = predict(\n",
    "    main_data,\n",
    "    reference_chips,\n",
    "    watershed_params,\n",
    "    models[model_idx],\n",
    "    device,\n",
    "    band_concatenators[model_idx],\n",
    "    lossFn,\n",
    "    create_lookup_table=True,\n",
    ")\n",
    "\n",
    "# Or predict for all reference image combinations as inputs\n",
    "# predictions = predict_for_all_pairs(\n",
    "#     main_data, reference_data, models[model_idx], device, band_concatenators[model_idx],\n",
    "#     lossFn, watershed_params, skip_retrieval=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: if you have run the above code for all reference combinations\n",
    "# preds = predictions[before_date, earlier_date]\n",
    "\n",
    "# if predicting on larger than 128x128 and want to crop to center 128x128\n",
    "row, col = crop_size // 2, crop_size // 2\n",
    "\n",
    "half_crop = 64  # we want middle 128x128\n",
    "xmin = row - half_crop\n",
    "xmax = row + half_crop\n",
    "ymin = col - half_crop\n",
    "ymax = col + half_crop\n",
    "extent = [xmin, xmax, ymin, ymax]\n",
    "\n",
    "rgb_main = get_rgb_bands(main_data[\"crop_arrays\"], BANDS)\n",
    "rgb_before = get_rgb_bands(before_data[\"crop_arrays\"], BANDS)\n",
    "rgb_earlier = get_rgb_bands(earlier_data[\"crop_arrays\"], BANDS)\n",
    "\n",
    "ratio_main = get_band_ratio(main_data[\"crop_arrays\"], BANDS)\n",
    "ratio_before = get_band_ratio(before_data[\"crop_arrays\"], BANDS)\n",
    "ratio_earlier = get_band_ratio(earlier_data[\"crop_arrays\"], BANDS)\n",
    "\n",
    "date_main = main_data[\"tile_item\"].time.date().isoformat()\n",
    "date_before = before_data[\"tile_item\"].time.date().isoformat()\n",
    "date_earlier = earlier_data[\"tile_item\"].time.date().isoformat()\n",
    "\n",
    "plot = all_error_analysis_plots(\n",
    "    rgb_main=rgb_main,\n",
    "    rgb_before=rgb_before,\n",
    "    rgb_earlier=rgb_earlier,\n",
    "    ratio_main=ratio_main,\n",
    "    ratio_before=ratio_before,\n",
    "    ratio_earlier=ratio_earlier,\n",
    "    predicted_frac=prediction.marginal,\n",
    "    predicted_mask=prediction.mask,\n",
    "    conditional_pred=prediction.conditional,\n",
    "    binary_probability=prediction.binary_probability,\n",
    "    conditional_retrieval=prediction.conditional_retrieval,\n",
    "    masked_conditional_retrieval=prediction.masked_conditional_retrieval,\n",
    "    rescaled_retrieval=None,  # We will plot this in the Retrieval and quantification section\n",
    "    marginal_retrieval=prediction.marginal_retrieval,\n",
    "    watershed_segmentation_params=watershed_params,\n",
    "    dates=(date_main, date_before, date_earlier),\n",
    "    ratio_colorbar=Colorbar.SHARE,  # (0.65, 1.0),\n",
    "    ratio_diff_colorbar=Colorbar.SHARE,  # (-0.1, 0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### Export prediction to GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_predition_and_mask_to_geotiff(\n",
    "    unmasked_retrieval_mol_m2=prediction.marginal,\n",
    "    binary_mask=prediction.mask.astype(np.uint8),\n",
    "    main_item_transform=main_item.get_raster_meta(\"B12\")[\"transform\"],\n",
    "    crop_start_x=main_data[\"crop_params\"][\"B12\"][\"crop_start_x\"],\n",
    "    crop_start_y=main_data[\"crop_params\"][\"B12\"][\"crop_start_y\"],\n",
    "    main_item_crs=CRS.from_string(main_item.crs),\n",
    "    observation_date=target_date.date().isoformat(),\n",
    "    satellite_name=SatelliteID.S2.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Retrieval for the biggest plume in the center\n",
    "\n",
    "crop_x = main_data[\"crop_params\"][\"B12\"][\"crop_start_x\"]\n",
    "crop_y = main_data[\"crop_params\"][\"B12\"][\"crop_start_y\"]\n",
    "prediction.crop_x = crop_x\n",
    "prediction.crop_y = crop_y\n",
    "pred_info = prediction.asdict()\n",
    "\n",
    "timestamp = main_item.time\n",
    "\n",
    "crop_crs = CRS.from_string(main_item.crs)\n",
    "window = rasterio.windows.Window(crop_x, crop_y, crop_size, crop_size)\n",
    "crop_transform = rasterio.windows.transform(window, main_item.get_transform(\"B12\"))\n",
    "\n",
    "# Quantify plumes in retrieval\n",
    "plume_list = quantify_retrieval(\n",
    "    prediction.conditional_retrieval,\n",
    "    crop_transform,\n",
    "    crop_crs,\n",
    "    prediction.binary_probability,\n",
    "    timestamp.date().isoformat(),\n",
    "    floor_t=watershed_params.watershed_floor_threshold,\n",
    "    marker_t=watershed_params.marker_threshold,\n",
    ")\n",
    "\n",
    "if len(plume_list) == 0:\n",
    "    print(\"No plumes detected\")\n",
    "else:\n",
    "    print(f\"Found {len(plume_list)} plumes\")\n",
    "\n",
    "    # Get Retrieval for the biggest plume in the center\n",
    "    plume_list = sorted(plume_list, key=lambda x: x[\"properties\"][\"Q\"])[::-1]\n",
    "    center_plumes: PlumeInfo = []\n",
    "    for plume in plume_list:\n",
    "        plume_info = PlumeInfo(**plume[\"properties\"])\n",
    "\n",
    "        intersects = intersects_center(*plume_info.bbox, buffer=center_buffer)\n",
    "        if intersects:\n",
    "            pprint.pp(plume_info)\n",
    "            center_plumes.append(plume)\n",
    "\n",
    "    print(f\"{len(center_plumes)} plumes intersect the center with {center_buffer} pixels of buffer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Heatmap of Max Probability + Binary Plot for Each Reference Chip Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"1226\"\n",
    "model_idx = model_id.index(model_id)\n",
    "\n",
    "predictions = predict_for_all_pairs(\n",
    "    main_data,\n",
    "    reference_data,\n",
    "    models[model_idx],\n",
    "    device,\n",
    "    band_concatenators[model_idx],\n",
    "    lossFn,\n",
    "    watershed_params,\n",
    "    skip_retrieval=False,\n",
    ")\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [d[\"tile_item\"].time.date().isoformat() for d in reference_data]\n",
    "\n",
    "plot_max_proba_center_buffer_heatmap(\n",
    "    predictions=predictions,\n",
    "    dates=dates,\n",
    "    center_buffer=center_buffer,\n",
    "    satellite_id=\"S2\",\n",
    "    title=f'Model {model_id} for main={target_date.isoformat().split(\"T\")[0]}',\n",
    "    show_topk=5,\n",
    "    main_date=target_date.isoformat().split(\"T\")[0],\n",
    "    plot_binary_grid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Predict for multiple dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "main_data_all = {}\n",
    "reference_data_all = {}\n",
    "for item in stac_items[:]:\n",
    "    target_date = item.datetime  # .date().isoformat()\n",
    "    # target_date = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "\n",
    "    items = fetch_sentinel2_items_for_point(\n",
    "        lat=lat, lon=lon, query_datetime=target_date, crop_size=crop_size, sbr_notebook=True\n",
    "    )\n",
    "\n",
    "    main_data = crop_main_data(items, abs_client, s3_client, lat, lon, crop_size)\n",
    "    main_data_all[target_date] = main_data\n",
    "\n",
    "    main_item = main_data[\"tile_item\"]\n",
    "    print(f\"Main tile for {target_date}: USE {main_item.id}\")\n",
    "    reference_data = crop_reference_data(\n",
    "        items,\n",
    "        main_data,\n",
    "        abs_client,\n",
    "        s3_client,\n",
    "        lat,\n",
    "        lon,\n",
    "        crop_size,\n",
    "        required_num_previous_snapshots=num_snapshots,\n",
    "        max_bad_pixel_perc=max_bad_pixel_perc,\n",
    "    )\n",
    "    reference_data_all[target_date] = reference_data\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs, sums, avg_ref_counts = plot_normal_and_avg_strategy(\n",
    "    stac_items,\n",
    "    main_data_all,\n",
    "    reference_data_all,\n",
    "    phase0_release_dates,\n",
    "    models,\n",
    "    model_ids,\n",
    "    band_concatenators,\n",
    "    device,\n",
    "    lossFn,\n",
    "    watershed_params,\n",
    "    center_buffer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normal_and_avg_strategy_summary(sums, avg_ref_counts, model_ids, ylim=[-2, 60], buffer_width=center_buffer * 2 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# In detail: Inspection and Submission of individual dates (Q1 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare wind data once\n",
    "from src.utils import PROJECT_ROOT\n",
    "\n",
    "wind_data = pd.read_csv(PROJECT_ROOT / \"src\" / \"data\" / \"ancillary\" / \"wind_vectors_gt_vs_models_2025_sbr_sites.csv\")\n",
    "wind_data = wind_data[wind_data[\"sensor\"] == \"S2\"]\n",
    "wind_data[\"sensing_time\"] = pd.to_datetime(\n",
    "    wind_data[\"date\"] + \" \" + wind_data[\"overpass_time_utc\"], utc=True\n",
    ").dt.strftime(\"%Y-%m-%dT%H:%M:%S+0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client, _, _, _, s3_client = initialize_clients(False)\n",
    "abs_client = initialize_blob_service_client(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a single date to do inference\n",
    "# stac_idx = -9\n",
    "target_date = \"2025-02-29\"\n",
    "stac_idx = next(\n",
    "    (i for i, item in enumerate(items_for_entire_phase) if item.item.datetime.date().isoformat() == target_date), -1\n",
    ")\n",
    "\n",
    "# stac_idx=8\n",
    "target_date = items_for_entire_phase[stac_idx].time\n",
    "# target_date = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "print(target_date)\n",
    "print(stac_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_dates = [\n",
    "    *phase0_release_dates,\n",
    "    # \"2025-04-05\", # possible detection\n",
    "    # \"2025-03-24\", # detection\n",
    "    # \"2025-03-22\", # detection\n",
    "    \"2025-03-17\",  # cloudy ref\n",
    "    \"2025-03-16\",  # hazy\n",
    "    \"2025-03-14\",  # dark ratio, mean 0.773 (normal is ~0.83)\n",
    "    \"2025-03-12\",  # cloudy ref\n",
    "    \"2025-03-07\",  # cloudy ref\n",
    "    \"2025-03-04\",  # sus\n",
    "    \"2025-03-02\",  # dark ref\n",
    "    # \"2025-02-25\", # release date\n",
    "    # \"2025-02-22\", # release date\n",
    "    # \"2025-02-20\", # release date\n",
    "    \"2025-02-12\",  # cloudy ref\n",
    "    \"2025-02-07\",  # cloudy ref\n",
    "    \"2025-01-28\",  # cloudy ref\n",
    "    \"2025-01-16\",  # dark ratio, mean 0.814 (normal is ~0.83)\n",
    "    \"2025-01-08\",  # cloudy ref\n",
    "    \"2025-01-06\",  # cloudy ref\n",
    "    \"2024-12-27\",  # dark ratio, mean 0.800 (normal is ~0.83)\n",
    "    \"2024-12-24\",  # dark ratio, mean 0.814 (normal is ~0.83)\n",
    "    \"2024-12-07\",  # dark ratio, mean 0.801 (normal is ~0.83)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare main data\n",
    "main_data = crop_main_data(items_for_entire_phase, abs_client, s3_client, lat, lon, crop_size, main_idx=stac_idx)\n",
    "main_item = main_data[\"tile_item\"]\n",
    "print(f\"Main tile      {main_item.id}\")\n",
    "\n",
    "# Use reference images before/after the main date\n",
    "max_days_difference = 30  # 60\n",
    "reference_data_ = []\n",
    "for reference in reference_data:\n",
    "    tile_id = reference[\"tile_item\"].id\n",
    "\n",
    "    ref_date = reference[\"tile_item\"].time\n",
    "    ref_date_short = ref_date.isoformat().split(\"T\")[0]\n",
    "    if ref_date_short in exclude_dates:\n",
    "        print(f\"Reference img on {ref_date_short} is excluded         --> DONT USE\")\n",
    "        continue\n",
    "    # Calculate the absolute difference in time\n",
    "    time_difference = abs(main_item.time - ref_date)\n",
    "    print(time_difference)\n",
    "    print(time_difference.total_seconds())\n",
    "\n",
    "    # Check if the difference in days is within the threshold\n",
    "    # timedelta.days gives the difference purely in days (ignoring hours etc.)\n",
    "    if time_difference.days <= max_days_difference and time_difference.total_seconds() > (max_seconds := 60):\n",
    "        reference_data_.append(reference)\n",
    "        print(f\"Reference img on {ref_date_short} is {time_difference.days:3} days distant -->      USE\")\n",
    "    else:\n",
    "        print(f\"Reference img on {ref_date_short} is {time_difference.days:3} days distant --> DONT USE\")\n",
    "len(reference_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Wind for Main Date\n",
    "sensing_time = main_item.time  # .isoformat()\n",
    "print(sensing_time)\n",
    "wind_components = get_wind_components(wind_data, sensing_time)\n",
    "\n",
    "u_wind_component, v_wind_component = wind_components[\"geos\"]\n",
    "wind_speed_geos = calc_effective_wind_speed(u_wind_component, v_wind_component)\n",
    "wind_direction_geos = calc_wind_direction(u_wind_component, v_wind_component)\n",
    "\n",
    "u_wind_component, v_wind_component = wind_components[\"era5\"]\n",
    "wind_speed_era5 = calc_effective_wind_speed(u_wind_component, v_wind_component)\n",
    "wind_direction_era5 = calc_wind_direction(u_wind_component, v_wind_component)\n",
    "\n",
    "print(\"GEOS Wind\")\n",
    "plot_wind(\n",
    "    lon,\n",
    "    lat,\n",
    "    main_item,\n",
    "    abs_client,\n",
    "    wind_speed_geos,\n",
    "    wind_direction_geos,\n",
    "    satellite_id=SatelliteID.S2,\n",
    "    arrow_scale_factor=500,\n",
    ")\n",
    "print(\"ERA5 Wind\")\n",
    "plot_wind(\n",
    "    lon,\n",
    "    lat,\n",
    "    main_item,\n",
    "    abs_client,\n",
    "    wind_speed_era5,\n",
    "    wind_direction_era5,\n",
    "    satellite_id=SatelliteID.S2,\n",
    "    arrow_scale_factor=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Main    date = {main_item.datetime_.isoformat().split('T')[0]}\")\n",
    "before_date = None\n",
    "earlier_date = None\n",
    "for reference in reference_data:\n",
    "    tile_id = reference[\"tile_item\"].id\n",
    "    # ref_date = datetime.strptime(tile_id.split(\"_\")[3], \"%Y%m%d\")\n",
    "    ref_date = reference[\n",
    "        \"tile_item\"\n",
    "    ].time  # datetime.strptime(reference[\"tile_item\"].item.datetime.date().isoformat(), \"%Y-%m-%d\")\n",
    "    ref_date_short = ref_date.isoformat().split(\"T\")[0]\n",
    "    # Calculate the absolute difference in time\n",
    "    time_difference = target_date - ref_date\n",
    "    if time_difference.days <= 0:\n",
    "        continue\n",
    "    if ref_date_short in exclude_dates:\n",
    "        print(f\"Reference img on {ref_date_short} is excluded         --> DONT USE\")\n",
    "        continue\n",
    "    if before_date is None:  # Closest is Before (t-1)\n",
    "        before_date = ref_date  # .isoformat().split(\"T\")[0]\n",
    "        print(f\"Before  date = {before_date}\")\n",
    "    elif earlier_date is None:  # Next closest is Earlier (t-2)\n",
    "        earlier_date = ref_date  # .isoformat().split(\"T\")[0]\n",
    "        print(f\"Earlier date = {earlier_date}\")\n",
    "        break\n",
    "\n",
    "# Optionally overwrite them (need the exact timestamp as well, or will need to manually modify code\n",
    "# i.e the dict keys in predict_for_all_pairs)\n",
    "# from datetime import timezone\n",
    "# before_date = datetime(2024, 10, 20, 18, 3, 9, 24000, tzinfo=timezone.utc)\n",
    "# earlier_date = datetime(2024, 9, 25, 18, 1, 11, 24000, tzinfo=timezone.utc)\n",
    "print(f\"Before  date = {before_date.isoformat()}\")\n",
    "print(f\"Earlier date = {earlier_date.isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Inspecting every combination of model and reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = crop_size // 2, crop_size // 2\n",
    "\n",
    "half_crop = 64  # we want middle 128x128\n",
    "xmin = row - half_crop\n",
    "xmax = row + half_crop\n",
    "ymin = col - half_crop\n",
    "ymax = col + half_crop\n",
    "extent = [xmin, xmax, ymin, ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reference_days_diffs = [30, 20, 15, 10, 5]\n",
    "\n",
    "# Visualize predictions using all reference image combinations as inputs\n",
    "output_preds = {}\n",
    "dates = [d[\"tile_item\"].time for d in reference_data_]\n",
    "for model_idx, model_id in enumerate(model_ids):\n",
    "    main_date = target_date.isoformat().split(\"T\")[0]\n",
    "    avg_preds = {}\n",
    "    for avg_reference_days_diff in avg_reference_days_diffs:\n",
    "        # Use reference images before/after the main date\n",
    "        reference_data_for_avg = get_reference_data(\n",
    "            reference_data, target_date, max_days_difference=avg_reference_days_diff\n",
    "        )\n",
    "        # Data preparation for predicting with average last 10 reference images\n",
    "        valid_refs = [\n",
    "            ref for ref in reference_data_for_avg if ref[\"tile_item\"].time.date().isoformat() not in exclude_dates\n",
    "        ]\n",
    "        print(\n",
    "            f\"Ref images {avg_reference_days_diff} before/after: Filtered {len(reference_data_for_avg)} refs to \"\n",
    "            f\"{len(valid_refs)} after excluding dates\"\n",
    "        )\n",
    "        avg_ref_count = len(valid_refs)\n",
    "        data_avg = copy.copy(reference_data_for_avg[0])\n",
    "        data_avg[\"crop_arrays\"] = np.mean([ref[\"crop_arrays\"] for ref in valid_refs], axis=0)\n",
    "        center_y = data_avg[\"crop_arrays\"][:, xmin:xmax, ymin:ymax].shape[1] // 2\n",
    "        center_x = data_avg[\"crop_arrays\"][:, xmin:xmax, ymin:ymax].shape[2] // 2\n",
    "\n",
    "        f, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        preds_avg = predict(\n",
    "            main_data,\n",
    "            [data_avg, data_avg],\n",
    "            watershed_params,\n",
    "            models[model_idx],\n",
    "            device,\n",
    "            band_concatenators[model_idx],\n",
    "            lossFn,\n",
    "        )\n",
    "        ratio_main = get_band_ratio(preds_avg.x_dict[\"crop_main\"][0], BANDS)[xmin:xmax, ymin:ymax]  # type:ignore\n",
    "        vmin = np.percentile(ratio_main, 0.5)\n",
    "        vmax = np.percentile(ratio_main, 99.5)\n",
    "\n",
    "        ratio_before = get_band_ratio(preds_avg.x_dict[\"crop_before\"][0], BANDS)[xmin:xmax, ymin:ymax]  # type:ignore\n",
    "        ratio_earlier = get_band_ratio(preds_avg.x_dict[\"crop_earlier\"][0], BANDS)[xmin:xmax, ymin:ymax]  # type:ignore\n",
    "\n",
    "        ax[0].imshow(ratio_earlier, vmin=vmin, vmax=vmax)\n",
    "        ax[0].set_title(\n",
    "            f\"Avg({avg_reference_days_diff} days before/after main) = {avg_ref_count} refs\\n\"\n",
    "            f\"Min {ratio_before.min():.2f} Max {ratio_before.max():.2f} \"\n",
    "            f\"Mean {ratio_earlier.mean():.3f}\",\n",
    "            fontsize=15,\n",
    "        )\n",
    "        ax[1].imshow(ratio_before, vmin=vmin, vmax=vmax)\n",
    "        ax[1].set_title(\n",
    "            f\"Avg({avg_reference_days_diff} days before/after main) = {avg_ref_count} refs\\n\"\n",
    "            f\"Min {ratio_before.min():.2f} Max {ratio_before.max():.2f} \"\n",
    "            f\"Mean {ratio_before.mean():.3f}\",\n",
    "            fontsize=15,\n",
    "        )\n",
    "        ax[2].imshow(ratio_main, vmin=vmin, vmax=vmax)\n",
    "        ax[2].set_title(\n",
    "            f\"Main Ratio {main_date}\\nMin {ratio_main.min():.2f} Max {ratio_main.max():.2f} \"\n",
    "            f\"Mean {ratio_main.mean():.3f}\",\n",
    "            fontsize=15,\n",
    "        )\n",
    "        ax[3].imshow(preds_avg.binary_probability[xmin:xmax, ymin:ymax], vmin=0.0, vmax=1.0, cmap=\"hot_r\")\n",
    "\n",
    "        center = get_center_buffer(preds_avg.binary_probability, center_buffer)\n",
    "        avg_preds[avg_reference_days_diff] = {\n",
    "            \"avg_ref_count\": avg_ref_count,\n",
    "            \"max_prob\": 100 * center.max(),\n",
    "            \"sum_prob\": 100 * center.sum() / (center.shape[0] * center.shape[1]),\n",
    "        }\n",
    "        ax[3].set_title(\n",
    "            f\"Avg({avg_reference_days_diff} days before/after main)\\nCenter sum(Prob): \"\n",
    "            f\"{100 * center.sum() / (center.shape[0] * center.shape[1]):.1f}%, \"\n",
    "            f\"Max: {100 * center.max():.0f}%\",\n",
    "            fontsize=16,\n",
    "        )\n",
    "        ax[0].scatter(center_x, center_y, color=\"green\", marker=\"x\")\n",
    "        ax[1].scatter(center_x, center_y, color=\"green\", marker=\"x\")\n",
    "        ax[2].scatter(center_x, center_y, color=\"green\", marker=\"x\")\n",
    "        ax[3].scatter(center_x, center_y, color=\"green\", marker=\"x\")\n",
    "        grid16(ax[0])\n",
    "        grid16(ax[1])\n",
    "        grid16(ax[2])\n",
    "        grid16(ax[3])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Model {model_id}\")\n",
    "    for k, v in avg_preds.items():\n",
    "        print(\n",
    "            f\"Avg{k}   Center sum(Prob): {v['sum_prob']:4.1f}%, \"\n",
    "            f\"Max: {v['max_prob']:3.0f}% (using avg of {v['avg_ref_count']} ref images)\"\n",
    "        )\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    predictions = predict_for_all_pairs(\n",
    "        main_data,\n",
    "        reference_data_,\n",
    "        models[model_idx],\n",
    "        device,\n",
    "        band_concatenators[model_idx],\n",
    "        lossFn,\n",
    "        watershed_params,\n",
    "        skip_retrieval=True,\n",
    "    )\n",
    "    output_preds[model_id] = plot_max_proba_center_buffer_heatmap(\n",
    "        predictions=predictions,\n",
    "        dates=dates,\n",
    "        center_buffer=center_buffer,\n",
    "        title=f\"Model {model_id} for main={main_date}\",\n",
    "        show_topk=5,\n",
    "        topk_based_on=\"max\",  # or \"sum\" to use the sum of center probabilities\n",
    "        satellite_id=SatelliteID.S2,\n",
    "        main_date=target_date.isoformat().split(\"T\")[0],\n",
    "        before_date=before_date,\n",
    "        earlier_date=earlier_date,\n",
    "        plot_topk=True,  # True,\n",
    "        plot_max_grid=True,  # True,\n",
    "        plot_binary_grid=False,\n",
    "        extent=extent,\n",
    "    )\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "1. Validate and visualize the plumes and emission rates of \"normal\" predictions, topk predictions or any other combination. Build the combination list `combinations_to_visualize` you want to test and call `validate_pred_retrievals(combinations_to_visualize)`.\n",
    "2. Manually select the combination of model id + before/earlier dates we will use for L/IME/Emission Rate Calculation + Unmasked Retrieval and plume mask .tif outputs. Put this into the decision_dict for the main date, e.g. `'selected_retrieval': {'model_id': '37', 'date_before': '2024-12-25', 'date_earlier': '2024-12-18'}`\n",
    "    1. Set `feasible` to True if we are able to predict for this main date, i.e. its not cloudy/cloud shadowy\n",
    "    2. Set `note` to \"no_detection\" or \"detection\" and any other notes you have.\n",
    "    3. Set `watershed_marker_t` and `watershed_floor_t` to your selected watershed parameters if you want different parameters from the default `watershed_marker_t=0.2`,`watershed_floor_t=0.15`\n",
    "    4. Set `selected_retrieval` as described above\n",
    "    5. If you have a detection: Set `wind_source` to \"era5\" or \"geos\"\n",
    "    6. If you have a detection: Set `emission_ensemble_selections` to a list of model id + before/earlier dates whose emission rates will be used to calculate our emission rate uncertainty. __Don't put the selected retrieval in here.__\n",
    "4. Run `sbr_form_outputs()` to get the values ready for copying into the form fillout. This will also export the needed unmasked retrieval and the binary plume mask .tifs from your `selected_retrieval`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## Retrieval and quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to initialize the RadTranLookup for the main date\n",
    "granule_item = main_data[\"tile_item\"]\n",
    "if isinstance(granule_item, LandsatGranuleAccess):\n",
    "    hapi_data_path = LANDSAT_HAPI_DATA_PATH\n",
    "elif isinstance(granule_item, Sentinel2Item):\n",
    "    hapi_data_path = S2_HAPI_DATA_PATH\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported granule access type: {type(granule_item)}\")\n",
    "lookup_table = RadTranLookupTable.from_params(\n",
    "    instrument=granule_item.instrument,\n",
    "    solar_angle=granule_item.solar_angle,\n",
    "    observation_angle=granule_item.observation_angle,\n",
    "    hapi_data_path=hapi_data_path,\n",
    "    min_ch4=0.0,\n",
    "    max_ch4=21.0,  # this value was selected based on the common value ranges of the sim plume datasets\n",
    "    spacing_resolution=40000,\n",
    "    ref_band=granule_item.swir16_band_name,\n",
    "    band=granule_item.swir22_band_name,\n",
    "    full_sensor_name=granule_item.sensor_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the combinations you want to validate/visualize\n",
    "combinations_to_visualize = []\n",
    "for model_id, v in output_preds.items():\n",
    "    if model_id in []:  # skip certain models\n",
    "        continue\n",
    "    top_n = 3\n",
    "    for j in range(1, top_n + 1):  # 6): # use topX dates\n",
    "        combinations_to_visualize.append(\n",
    "            {\n",
    "                \"model_id\": model_id,\n",
    "                \"date_before\": v[f\"top_{j}\"][\"date_before\"],\n",
    "                \"date_earlier\": v[f\"top_{j}\"][\"date_earlier\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # visualize the \"normal\" predictions\n",
    "    combinations_to_visualize.append(\n",
    "        {\"model_id\": model_id, \"date_before\": v[\"normal\"][\"date_before\"], \"date_earlier\": v[\"normal\"][\"date_earlier\"]}\n",
    "    )\n",
    "combinations_to_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience cell to prepare the selected ensemble\n",
    "# for copy-pasting into the decisions dict\n",
    "import rich  # may need to pip install\n",
    "\n",
    "# Sort combinations_to_visualize by model_id, then date_before, then date_earlier\n",
    "# remove selected model from ensemble\n",
    "combinations_for_ensemble = combinations_to_visualize[:-1]\n",
    "combinations_for_ensemble = sorted(\n",
    "    combinations_for_ensemble, key=lambda x: (x[\"model_id\"], x[\"date_before\"], x[\"date_earlier\"])\n",
    ")\n",
    "\n",
    "rich.print(combinations_for_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_params = WatershedParameters(\n",
    "    marker_distance=1,\n",
    "    marker_threshold=0.2,\n",
    "    watershed_floor_threshold=0.05,\n",
    "    closing_footprint_size=0,\n",
    ")\n",
    "max_distance_pixels = 10\n",
    "pixel_width = 30\n",
    "wind_speed = wind_speed_era5  # or wind_speed_geos\n",
    "\n",
    "validate_pred_retrievals(\n",
    "    combinations_to_visualize,\n",
    "    main_data,\n",
    "    reference_data,\n",
    "    model_ids,\n",
    "    watershed_params,\n",
    "    models,\n",
    "    device,\n",
    "    band_concatenators,\n",
    "    lossFn,\n",
    "    lookup_table,\n",
    "    wind_speed,\n",
    "    satellite_id=SatelliteID.S2,\n",
    "    max_distance_pixels=max_distance_pixels,\n",
    "    pixel_width=pixel_width,\n",
    "    show_plots=False,\n",
    ")\n",
    "validate_pred_retrievals(\n",
    "    combinations_to_visualize,\n",
    "    main_data,\n",
    "    reference_data,\n",
    "    model_ids,\n",
    "    watershed_params,\n",
    "    models,\n",
    "    device,\n",
    "    band_concatenators,\n",
    "    lossFn,\n",
    "    lookup_table,\n",
    "    wind_speed,\n",
    "    satellite_id=SatelliteID.S2,\n",
    "    max_distance_pixels=max_distance_pixels,\n",
    "    pixel_width=pixel_width,\n",
    "    show_plots=True,\n",
    "    extent=extent,\n",
    "    skip_plot_if_no_central_plume=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_date, earlier_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## Decisions and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions_dict = {\n",
    "    \"2025-01-01T18:16:49.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1422\",\n",
    "            \"date_before\": \"2024-12-14T18:07:51.024000+00:00\",\n",
    "            \"date_earlier\": \"2024-12-12T18:16:59.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-03T18:07:41.024000+00:00\": {\n",
    "        \"note\": \"no_detection\",\n",
    "        \"feasible\": True,\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-01-01T18:16:49.024000+00:00\",\n",
    "            \"date_earlier\": \"2024-12-14T18:07:51.024000+00:00\",\n",
    "        },\n",
    "    },\n",
    "    \"2025-01-06T18:17:31.024000+00:00\": {\n",
    "        \"feasible\": False,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-08T18:06:29.024000+00:00\": {\n",
    "        \"feasible\": False,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-11T18:16:29.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1422\",\n",
    "            \"date_before\": \"2025-01-26T18:16:51.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-26T18:16:51.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-13T18:07:11.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-01-11T18:16:29.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-03T18:07:41.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-16T18:17:11.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1486\",\n",
    "            \"date_before\": \"2025-01-26T18:16:51.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-21T18:15:49.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-18T18:05:59.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no-detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-01-13T18:07:11.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-11T18:16:29.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-21T18:15:49.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no-detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-01-18T18:05:59.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-13T18:07:11.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-26T18:16:51.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no-detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-01-21T18:15:49.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-18T18:05:59.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-28T18:05:19.024000+00:00\": {\n",
    "        \"feasible\": False,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-01-31T18:15:09.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1422\",\n",
    "            \"date_before\": \"2025-01-01T18:16:49.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-02-15T18:15:01.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-02T18:06:01.024000+00:00\": {\n",
    "        \"feasible\": False,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-05T18:16:01.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-01-31T18:15:09.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-26T18:16:51.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-07T18:04:19.024000+00:00\": {\n",
    "        \"feasible\": False,  # CLOUDS\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-12T18:05:11.025000+00:00\": {\n",
    "        \"feasible\": False,  # CLOUDS\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-15T18:15:01.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1475\",\n",
    "            \"date_before\": \"2025-02-05T18:16:01.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-01-31T18:15:09.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-17T18:03:19.024000+00:00\": {\n",
    "        \"feasible\": False,  # CLOUDS\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-20T18:13:09.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1340\",\n",
    "            \"date_before\": \"2025-01-21T18:15:49.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-09T18:00:59.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-22T18:04:01.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1486\",\n",
    "            \"date_before\": \"2025-02-05T18:16:01.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-02-25T18:13:51.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-25T18:13:51.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1486\",\n",
    "            \"date_before\": \"2025-02-22T18:04:01.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-02-20T18:13:09.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-02-27T18:02:09.024000+00:00\": {\n",
    "        \"feasible\": False,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-02T18:11:49.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1475\",\n",
    "            \"date_before\": \"2025-02-15T18:15:01.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-29T17:59:09.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.16,\n",
    "    },\n",
    "    \"2025-03-04T18:02:51.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1475\",\n",
    "            \"date_before\": \"2025-03-16T18:07:51.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-29T17:59:09.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-07T18:12:41.025000+00:00\": {\n",
    "        \"feasible\": False,  # CLOUDS\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-09T18:00:59.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-02-25T18:13:51.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-02-22T18:04:01.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-12T18:10:39.024000+00:00\": {\n",
    "        \"feasible\": False,  # CLOUDS\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-14T18:01:41.024000+00:00\": {\n",
    "        \"feasible\": False,  # WEIRD DARK ALBEDO\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-16T18:07:51.024000+00:00\": {\n",
    "        \"feasible\": False,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1486\",\n",
    "            \"date_before\": \"2025-03-24T18:00:31.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-04T18:02:51.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-17T18:11:21.025000+00:00\": {\n",
    "        \"feasible\": False,  # CLOUDS\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {},\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-19T17:59:49.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1226\",\n",
    "            \"date_before\": \"2025-03-29T17:59:09.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-04-06T18:09:41.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-22T18:09:29.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1486\",\n",
    "            \"date_before\": \"2025-04-11T18:09:19.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-16T18:07:51.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-24T18:00:31.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1486\",\n",
    "            \"date_before\": \"2025-03-29T17:59:09.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-22T18:09:29.024000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-27T18:10:11.025000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1422\",\n",
    "            \"date_before\": \"2025-04-11T18:09:19.024000+00:00\",\n",
    "            \"date_earlier\": \"2025-04-06T18:09:41.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-29T17:59:09.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1422\",\n",
    "            \"date_before\": \"2025-03-27T18:10:11.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-24T18:00:31.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "    \"2025-03-29T18:17:51.024000+00:00\": {\n",
    "        \"feasible\": True,\n",
    "        \"note\": \"no_detection\",\n",
    "        \"wind_source\": \"era5\",\n",
    "        \"emission_ensemble_selections\": [],\n",
    "        \"selected_retrieval\": {\n",
    "            \"model_id\": \"1475\",\n",
    "            \"date_before\": \"2025-03-27T18:10:11.025000+00:00\",\n",
    "            \"date_earlier\": \"2025-03-24T18:00:31.025000+00:00\",\n",
    "        },\n",
    "        \"watershed_marker_t\": 0.2,\n",
    "        \"watershed_floor_t\": 0.15,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items_for_entire_phase:\n",
    "    print(item.time.isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can take some time, and we don't want the client to expire\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils import PROJECT_ROOT\n",
    "\n",
    "# delete current submission outputs so we can overwrite\n",
    "output_dir = PROJECT_ROOT / \"sbr_2025\" / \"notebooks\" / \"data\" / \"submission_geotiffs\" / \"phase1_submission\"\n",
    "if output_dir.exists() and output_dir.is_dir():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "assert output_dir.is_dir()\n",
    "\n",
    "ml_client, _, _, _, s3_client = initialize_clients(False)\n",
    "abs_client = initialize_blob_service_client(ml_client)\n",
    "\n",
    "main_data = crop_main_data(items_for_entire_phase, abs_client, s3_client, lat, lon, crop_size, main_idx=0)\n",
    "print(main_data[\"tile_item\"].time)\n",
    "\n",
    "reference_data = crop_reference_data(\n",
    "    items_for_entire_phase,\n",
    "    main_data,\n",
    "    abs_client,\n",
    "    s3_client,\n",
    "    lat,\n",
    "    lon,\n",
    "    crop_size,\n",
    "    required_num_previous_snapshots=num_snapshots,\n",
    "    max_bad_pixel_perc=max_bad_pixel_perc,\n",
    ")\n",
    "\n",
    "for dt, decision in decisions_dict.items():\n",
    "    if not decision.get(\"feasible\"):\n",
    "        continue\n",
    "\n",
    "    stac_idx = next((i for i, item in enumerate(items_for_entire_phase) if item.time.isoformat() == dt), -1)\n",
    "    main_data = crop_main_data(items_for_entire_phase, abs_client, s3_client, lat, lon, crop_size, main_idx=stac_idx)\n",
    "    print(f\"----: {dt} - {stac_idx}\")\n",
    "\n",
    "    sbr_form_outputs(\n",
    "        decision,\n",
    "        wind_data,\n",
    "        model_ids,\n",
    "        models,\n",
    "        device,\n",
    "        band_concatenators,\n",
    "        main_data,\n",
    "        reference_data,  # send through all reference data\n",
    "        lossFn,\n",
    "        lookup_table,\n",
    "        max_distance_pixels,\n",
    "        pixel_width,\n",
    "        SatelliteID.S2,\n",
    "        abs_client,\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-paste output path of enhancement tif to visualise\n",
    "\n",
    "\n",
    "for tif in sorted(list(Path(\"data/submission_geotiffs/phase1_submission/\").glob(\"**/*.tif\"))):\n",
    "    with rasterio.open(tif) as ds:\n",
    "        enhancement = ds.read(1)\n",
    "        plt.imshow(enhancement, cmap=\"plasma\", vmin=0, vmax=2)  # using same color scale as in the 2024 Sherwin paper\n",
    "        plt.title(tif.name)\n",
    "        plt.colorbar(label=\"Enhancement (ppm)\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
